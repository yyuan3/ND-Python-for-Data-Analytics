{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python for Data Analytics | Module 6\n",
    "<br>Professor James Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learing with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Datasets available in the package\n",
    "\n",
    "The scikit-learn package has datasets available in the library which makes it is easy to practice and learn even if you don't have external data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Breast cancer dataset\n",
    "\n",
    "Let's load a sample dataset that is already available in the package and can be loaded by just calling `load_breast_cancer()` method. The source of this data is https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE HOW THE FOLLOWING CODE WORKS BUT CONCENTRATE ON THE HOW THE DATA LOOKS\n",
    "# Convert the data into a DataFrame\n",
    "\n",
    "cancer_df = pd.DataFrame(cancer.data, columns=[cancer.feature_names])\n",
    "cancer_df['Target'] = pd.Series(cancer.target)\n",
    "\n",
    "# In case you want labels instead of numbers.\n",
    "cancer_df.replace(to_replace={'Target': {0: cancer.target_names[0]}}, inplace=True)\n",
    "cancer_df.replace(to_replace={'Target': {1: cancer.target_names[1]}}, inplace=True)\n",
    "\n",
    "cancer_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "Dataset of incidence of high blood pressure among a sample of adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_data = pd.read_csv(\"https://www3.nd.edu/~jng2/bp_classific.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot to understand the relationshp between features\n",
    "\n",
    "You can specific the column you want to use for classification (in this case `high_bp`) as `hue` parameter to distinguish between one class to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bp_data, hue='high_bp', diag_kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the input features and outcome variable\n",
    "\n",
    "bp_data_X = bp_data.drop('high_bp',axis = 1)\n",
    "bp_data_Y = bp_data['high_bp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_data_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split()`: Method to split the data into train and test\n",
    "\n",
    "Split the data randomly into training set to learn a classifier and then a test set to validate how good our model is \n",
    "\n",
    "Important parameters to this method\n",
    "\n",
    "* **random_state**: Seed to be used by randomizer to randomly split the data. Set to the same number each run if you want to reproduce results.\n",
    "* **train_size**: Use float to specify what fraction to use for training. Usually 0.7, 0.75 or 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bp_train_X, bp_test_X, bp_train_Y, bp_test_Y = train_test_split(bp_data_X, \n",
    "                                                                bp_data_Y, \n",
    "                                                                random_state=42, \n",
    "                                                                train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bp_data_X), len(bp_train_X), len(bp_test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify with Gaussian naive Bayes. We will not delve into this algorithm here. This is just to illustrate \n",
    "# the general approach.\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(bp_train_X, bp_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_predict_Y = model.predict(bp_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklmetrics\n",
    "\n",
    "sklmetrics.accuracy_score(bp_test_Y, bp_predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklmetrics.confusion_matrix(bp_test_Y, bp_predict_Y, labels =[0,1])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(conf_mat, square=True, annot=True, cbar = False)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"True Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the above case we can see that we have \n",
    "\n",
    "Good cases:\n",
    "* **True Negatives**: 10 cases where the true value was No High BP (high_bp = 0) and we predicted that there will be No High BP \n",
    "* **True Positives**: 14 cases where the true value was High BP (high_bp = 1) and we predicted that there will be High BP \n",
    "\n",
    "Bad cases:\n",
    "* **False Positives**: 4 cases where the true value was No High BP (high_bp = 0) and we predicted that there will be High BP (TYPE I ERROR)\n",
    "* **False Negatives**: 2 cases where the true value was High BP (high_bp = 1) and we predicted that there will be No High BP (TYPE II ERROR)\n",
    "\n",
    "Think about the real-world consequence of making both these these two types of errors. Is Type I Error or Type II Error worse? It depends! Here most people would say Type II Error is worse (patient who actually has high BP is misdiagnosed as having normal BP so condition left untreated). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity\n",
    "\n",
    "We will use the breast cancer data available in scikit-learn to predict if an biopsy image is cancerous or not. \n",
    "\n",
    "Follow these steps (steps 1 and 2 are done for you)\n",
    "1. Load the data \n",
    "2. Separate X (input features) and Y (outcome)\n",
    "3. Split into training data and test data. Use 80% of data for training\n",
    "    * Verify if the data is appropriately split by checking the number of rows in each of the training and test data. \n",
    "4. Learn the GaussianNB classifier to predict cancer or malignant\n",
    "5. Predict using the test data\n",
    "6. Provide accuracy score as well as plot the confusion matrix\n",
    "    * Think about the consequence of False Positives and False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "\n",
    "cancer = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Separate X (input features) and Y (outcome)\n",
    "\n",
    "cancer_X = cancer.data\n",
    "cancer_Y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split into training data and test data\n",
    "\n",
    "cancer_train_X, cancer_test_X, cancer_train_Y, cancer_test_Y = train_test_split(cancer_X, cancer_Y, random_state=123, \n",
    "                                                                               train_size = 0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cancer_X), len(cancer_train_X), len(cancer_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cancer = GaussianNB()\n",
    "\n",
    "model_cancer.fit(cancer_train_X, cancer_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_predict_Y = model_cancer.predict(cancer_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklmetrics.confusion_matrix(cancer_test_Y, cancer_predict_Y, labels =[0,1])\n",
    "conf_mat\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cbar = False)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"True Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklmetrics.accuracy_score(cancer_test_Y, cancer_predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = (cancer_test_Y == cancer_predict_Y)\n",
    "print(matches.sum())\n",
    "print(len(matches))\n",
    "matches.sum() / float(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Unsupervised Learning\n",
    "\n",
    "The example below is borrowed from your textbook. \n",
    "\n",
    "'Unsupervised' means the Target variable is not labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and visualizing the digits data\n",
    "\n",
    "We'll use Scikit-Learn's data access interface and take a look at this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE HOW THE FOLLOWING CODE WORKS BUT CONCENTRATE ON THE HOW THE DATA LOOKS\n",
    "# Convert the data into a DataFrame\n",
    "\n",
    "digits_df = pd.DataFrame(digits.data)\n",
    "digits_df['Target'] = pd.Series(digits.target)\n",
    "digits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images data is a three-dimensional array: 1,797 samples each consisting of an 8 × 8 grid of pixels.\n",
    "Let's visualize the first hundred of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT DWELL ON HOW THE IMAGES ARE LOADED\n",
    "## CONCENTRATE ON THE IMAGES THAT ARE PRODUCED AS OUTPUT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into X (input characteristics) and Y (outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_X = digits.data\n",
    "digit_Y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "If a dataset has say 1000 columns, can the essential features of the data be represnted by fewer columns? To check this, we use dimensionality reduction techniques.\n",
    "\n",
    "We often use dimensionality reduction to aid in visualizing data: after all, it is much easier to plot data in two dimensions than in three dimensions or higher!\n",
    "\n",
    "Here we will use principal component analysis (PCA) to reduce the dimension of the digits data. We will ask the model to return two 'components' —that is, a two-dimensional representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA  \n",
    "model = PCA(n_components=2)            \n",
    "model.fit(digit_X)     \n",
    "print(model.explained_variance_ratio_)\n",
    "\n",
    "X_2D = model.transform(digit_X)\n",
    "\n",
    "digits_df['PCA1'] = X_2D[:, 0]\n",
    "digits_df['PCA2'] = X_2D[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the digits data (first two principal components) after dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\"PCA1\", \"PCA2\", hue='Target', data=digits_df, fit_reg=False, \n",
    "          palette = sns.color_palette(\"Set1\", n_colors=10, desat=.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning: clustering digits\n",
    "\n",
    "Let's next look at applying clustering to the digits data.\n",
    "A clustering algorithm attempts to find distinct groups of data without reference to any labels.\n",
    "Here we will use a powerful clustering method called a Gaussian mixture model (GMM). \n",
    "A GMM attempts to model the data as a collection of Gaussian blobs. \n",
    "\n",
    "We can fit the Gaussian mixture model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choose the model class\n",
    "from sklearn.mixture import GaussianMixture      \n",
    "# 2. Instantiate the model with hyperparameters. \n",
    "# We are building 10 clusters (n_components) because we believe there \n",
    "# may be 10 clusters, one for each digit\n",
    "model = GaussianMixture(n_components=10,\n",
    "            covariance_type='full')  \n",
    " # 3. Fit to data. Notice y is not specified!\n",
    "model.fit(digit_X)  \n",
    "# 4. Determine cluster labels\n",
    "y_gmm = model.predict(digit_X)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the clusters and dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again ignore the technical details, focus on the plot\n",
    "\n",
    "digits_df['cluster'] = y_gmm\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", data=digits_df, hue='Target',\n",
    "           col='cluster', fit_reg=False, col_wrap=3,\n",
    "          palette = sns.color_palette(\"Set1\", n_colors=10, desat=.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "The cluster digits may not correspond to the actual digits they represent. From the image, see if you can find which cluster number corresponds to which number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Getting back to Classification!\n",
    "\n",
    "Let's try to classify the digits data into corresponding integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "digit_X_train, digit_X_test, digit_Y_train, digit_Y_test = train_test_split(digit_X, \n",
    "                                                    digit_Y, \n",
    "                                                    random_state=123, \n",
    "                                                    train_size = 0.8, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "learndigits = GaussianNB()\n",
    "learndigits.fit(digit_X_train, digit_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the labels of the test data\n",
    "digit_Y_predicted = learndigits.predict(digit_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction\n",
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digit_X_test.reshape(-1, 8, 8)[i], cmap=plt.cm.binary,\n",
    "              interpolation='nearest')\n",
    "\n",
    "    # label the image with the target value\n",
    "    if digit_Y_predicted[i] == digit_Y_test[i]:\n",
    "        ax.text(0, 7, str(digit_Y_predicted[i]), color='green')\n",
    "    else:\n",
    "        ax.text(0, 7, str(digit_Y_predicted[i]), color='red')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklmetrics.confusion_matrix(digit_Y_test, digit_Y_predicted, labels = np.arange(0,10))\n",
    "conf_mat\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cbar = False)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"True Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklmetrics.accuracy_score(digit_Y_test, digit_Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What exactly was accuracy score?\n",
    "matches = (digit_Y_predicted == digit_Y_test)\n",
    "print(matches.sum())\n",
    "print(len(matches))\n",
    "matches.sum() / float(len(matches))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
