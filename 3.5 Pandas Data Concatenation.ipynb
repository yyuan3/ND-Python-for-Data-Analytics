{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3.5: Pandas Data Concatenation\n",
    "Python for Data Analytics | Module 3  \n",
    "Professor James Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: DO NOT CHANGE\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be covering basic ways to combine datasets using the `pd.concat()` function of the *pandas* library. Conceptually, it is related to the `pd.merge()` function that we will cover in the next tutorial in that they are both ways of combining different data sets. \n",
    "\n",
    "The mechanics of how they perform the combinations are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial, we will only need our college_loan_defaults dataset.\n",
    "college_loan_defaults = pd.read_csv('data-sets/college-loan-default-rates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.concat()`\n",
    "You can think of the `pd.concat()` function as the equivalent of the NumPy `concatenate()` function for `Series` and `DataFrame` objects. Essentially, the `pd.concat()` function appends new rows or columns to a *Series*/*DataFrame*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `pd.concat()` with a *DataFrame* most basic question is whether you are adding *additional rows* or *additional columns*. We'll run through the function arguments based on concatenating rows and then come back for a look at how we perform column concatentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating *DataFrame* Rows\n",
    "To get started, I'll split the college_loan_defaults into multiple sections of rows using the `.iloc` attribute that we will then stitch back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Notice that I've included numeric index 1999 both part_2 and part_3\n",
    "part_1 = college_loan_defaults.iloc[:1000]\n",
    "part_2 = college_loan_defaults.iloc[1000:2000]\n",
    "part_3 = college_loan_defaults.iloc[1999:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "Before we start, let's see how many rows are in each of are parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(part_1), len(part_2), len(part_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In it's simpliest form, all you need to pass to `pd.concat()` is a list of the *pandas* objects that you want to combine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all three parts back together with pd.concat()\n",
    "# Notice that I've put part 3 first here.\n",
    "concatenated_dataframe = pd.concat([part_3, part_1, part_2])\n",
    "\n",
    "# And print out the number of rows\n",
    "# Should be the sum of the individual parts\n",
    "len(concatenated_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. Now, take a look at the `head()` of the resulting *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look, part_3 is now at the head() of our DataFrame.\n",
    "# pd.concat() does not do any sorting of the indices.\n",
    "concatenated_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicate Index Values with `verify_integrity` & `ignore_index` Parameters\n",
    "I mentioned earlier, that I purposely shared an index value (1999) between the *part_2* and *part_3* objects.\n",
    "The result of this is that there are actually two rows with index 1999 in our *concatenated_dataframe* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataframe.loc[1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross, now we have to deal with the duplicate index value. \n",
    "\n",
    "If you want to keep both entries (often the case if the index value is the same but the rest of the data is different) you can pass the `ignore_index` parameter with a value of `True` to the function and all existing index values will be dumped and a new integer based index will be created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumpy the old index and generate a new one\n",
    "# Notice how the index values now start from 0, even though we\n",
    "# used `part_2` as the first object in this concat operation\n",
    "concatenated_dataframe = pd.concat([part_2, part_3, part_1], ignore_index=True)\n",
    "concatenated_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if we still have the data from both entries\n",
    "# AND ensure they have different index values\n",
    "mask = concatenated_dataframe['name'] == 'JOHN MARSHALL LAW SCHOOL (THE)'\n",
    "concatenated_dataframe[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we no longer have duplicate index values. **BUT** these two rows are pure duplicates of each other and in situations like this, you almost certainly want to keep just one. \n",
    "\n",
    "To check for duplicates use pandas's `duplicated()`.\n",
    "\n",
    "To drop duplicates use pandas's `drop_duplicates()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Column Mismatches with the `join` Parameter\n",
    "Sometimes you will have two sets of rows that you want to join together, but the sets don't have all of the same columns.\n",
    "\n",
    "To demonstrate, I'll create a couple of additional small *DataFrame* objects from our college loan dataset to demonstrate our options here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 1\n",
    "# Contains the first 5 rows of the original dataset\n",
    "# But only the name, city, and state columns\n",
    "name_city_state_columns_only = college_loan_defaults[['name', 'city', 'state']][:5]\n",
    "name_city_state_columns_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 2\n",
    "# Contains the second 5 rows of the original dataset\n",
    "# But only the name, state, and zipcode columns\n",
    "name_state_zipcode_columns_only = college_loan_defaults[['name', 'state', 'zipcode']][5:10]\n",
    "name_state_zipcode_columns_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have have 2 sets of 5 rows that we want to concatenate together, but they have different columns. Let's see what happens if you don't specify anything with the `join` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([name_city_state_columns_only, name_state_zipcode_columns_only])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that *pandas* combined the rows indices together as expected. In addition, it combined all the available column names **and** added `NaN` values for any index/column combination that didn't have a value in the original dataframes.\n",
    "\n",
    "Alternatively, we can tell *pandas* to drop any column(s) where there is not data for a given column in all of the objects being concatenated. You can do this be specifying a value of `inner` to the `join` parameter of the function.\n",
    "\n",
    "Let's demonstrate how doing so will result in only the shared columns (name, state) appearing in the final dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([name_city_state_columns_only, name_state_zipcode_columns_only], join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating `DataFrame` Columns\n",
    "Now let's go back and see how we can use the `pd.concat()` function to combine two sets of columns with the same index (row) values.\n",
    "\n",
    "As before, we will start with data small *DataFrame* objects. As we begin to work the results will start out a little dirty but we will clean it up with our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 1\n",
    "# Contains the first 5 rows of the original dataset\n",
    "# But only the name, city, and state columns\n",
    "\n",
    "# Doing a reverse sort on the index...\n",
    "name_city_state_zipcode_columns = college_loan_defaults[['name', 'city', 'state']][:5]\n",
    "name_city_state_zipcode_columns.sort_index(ascending=False, inplace=True)\n",
    "name_city_state_zipcode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 2\n",
    "# Contains the 7 rows of the original dataset\n",
    "# But only the name, state, and zipcode columns\n",
    "\n",
    "# Again, doing a reverse sort on the index.\n",
    "name_and_default_rates = college_loan_defaults[\n",
    "    ['year_1_default_rate', 'year_2_default_rate', 'year_3_default_rate']][:7]\n",
    "name_and_default_rates.sort_index(ascending=False, inplace=True)\n",
    "name_and_default_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a simple concatenation. To add columns we have to specify the `axis` parameter with a value of `1` or `columns` to indicate we are adding colums, not rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [name_city_state_zipcode_columns, name_and_default_rates], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of important things to notice here:\n",
    "* Unlike when concatenating rows, this time *pandas* did do an index sort after performing the combination. Just something to be aware of.\n",
    "* See how there are a couple of rows with `NaN` values for their first three colums? That's because our `name_and_default_rates` dataframe had two additional rows for which there were no corresponding values in `name_city_state_zipcode_columns`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we could specify an *inner join* to drop columns with missing data previously, we can use it here to drop rows with missing values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [name_city_state_zipcode_columns, name_and_default_rates], \n",
    "    axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's talk about the how the `verify_integrity` and `ignore_index` parameters would work when concatenating columns.\n",
    "\n",
    "Let's say that we had included the city column in both dataframes:\n",
    "* The default behavior of `pd.concat()` would have been to create a new dataframe with 2 \"city\" columns.\n",
    "* You could make Pandas throw a `ValueError` exception by passing `verify_integrity=True` to the function.\n",
    "* You could also throw out all the column names and replaced them with an 0-based series of integers by passing `ignore_index=True`.  This would result in the values of \"city\" being duplicated in two columns, but the columns would have different integer \"names\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating *Series* Objects\n",
    "Concatenating *Series* objects is really no different than concatenating a single column *DataFrame*. But, for the sake of completeness, here are some quick examples of `pd.concat()` on a *Series*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab two sections of the `name` Series\n",
    "series_index_0_to_5 = college_loan_defaults['name'][:6]\n",
    "series_index_5_to_10 = college_loan_defaults['name'][5:10]\n",
    "print(series_index_0_to_5, series_index_5_to_10, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them together with default argument values\n",
    "# Notice the duplicate 5 index\n",
    "pd.concat([series_index_0_to_5, series_index_5_to_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the duplicate `41833` index with `ignore_index`\n",
    "# Remember this generates a new numberic index\n",
    "pd.concat([series_index_0_to_5, series_index_5_to_10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or raise ValueError with `verify_integrity`\n",
    "pd.concat([series_index_0_to_5, series_index_5_to_10], verify_integrity=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
