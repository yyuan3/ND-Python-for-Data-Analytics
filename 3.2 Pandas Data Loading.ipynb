{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXbK-e5ledwn"
   },
   "source": [
    "# Tutorial 3.2: Pandas Data Loading\n",
    "Python for Data Analytics | Module 3  \n",
    "Professor James Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya7H8_Np9gwL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8JcIXtsedw2"
   },
   "source": [
    "So far in our course, I've taken care of loading all of the data sets that you've interacted with. **But that changes today!** In this tutorial, we will be going over a couple of different methods on how to load data into your notebooks with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQIMlAbtedw6"
   },
   "source": [
    "## Loading CSV Files with `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TC1tWLWGedw-"
   },
   "source": [
    "*Pandas* **`read_csv()`** function is likely to become one of your most used tools.  It creates a **`DataFrame`** object from a CSV file (surprise!). \n",
    "\n",
    "Let's go over the basics of using it and some of the common options you might want to specify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ao2T3HAoedw_"
   },
   "source": [
    "### Simple Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AoJ8hxXfHJU"
   },
   "outputs": [],
   "source": [
    "# Download the Chicago recent crime dataset from OSF\n",
    "!curl -L https://osf.io/u6xqa/download --create-dirs -o data-sets/chicago-recent-crime.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9y8Wz9UyedxD"
   },
   "outputs": [],
   "source": [
    "# In the simpliest case, all you have to do pass the \n",
    "# location of your CSV file to the function.\n",
    "chicago_crime = pd.read_csv('data-sets/chicago-recent-crime.csv')\n",
    "chicago_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_CaJwmFedxO"
   },
   "outputs": [],
   "source": [
    "# You can also point it directly at a csv or zipped csv file that is online.\n",
    "# Super cool! \n",
    "\n",
    "# BUT, this will be slow depending on the size of the CSV\n",
    "# and your connection speed. And if your internet connection\n",
    "# goes belly up, you are out of luck.\n",
    "online_csv = pd.read_csv(\n",
    "    'https://bulkdata.uspto.gov/data/trademark/assignment/economics/2016/tm_convey.csv.zip')\n",
    "online_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGqsMUmFedxX"
   },
   "source": [
    "### Specify an Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "373QeXIjedxZ"
   },
   "source": [
    "Text files are **encoded** in different formats when they are written. To read them, you must decode them with the same standard or you'll have a problem.\n",
    "\n",
    "For example, our `college-scorecard-data-scrubbed.csv` file was encoded using `latin-1`, but the default setting for Pandas in Python 3 is `utf-8` so we will get an error if we try to read the file without specify the correct encoding like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Am7lRH_Y3vON"
   },
   "outputs": [],
   "source": [
    "# Download the College Scorecard dataset from OSF\n",
    "!curl -L https://osf.io/cz253/download --create-dirs -o data-sets/college-scorecard-data-scrubbed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSAUad7Jedxc"
   },
   "outputs": [],
   "source": [
    "college_scorecard = pd.read_csv(\n",
    "    'data-sets/college-scorecard-data-scrubbed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bT6XBhEedxo"
   },
   "source": [
    "To avoid this error, we need to specify the correct encoding with the `encoding` parameter when we call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKoNzLsOedxr"
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with 'latin-1' encoding specified.\n",
    "college_scorecard = pd.read_csv(\n",
    "    'data-sets/college-scorecard-data-scrubbed.csv', encoding='latin-1') \n",
    "college_scorecard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUI3Dkms4Kaf"
   },
   "source": [
    "#### Tip: Encoding\n",
    "Text isn't actually stored in its natural form inside of your computer. Instead it is \"encoded\" into a format that the computer understands, but would look like gibberish to a human. \n",
    "\n",
    "Without knowing how a file was \"encoded\" you don't have a way to turn that gibberish back into readable text, which is called \"decoding\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSIDAGCgedx0"
   },
   "source": [
    "### Choosing an Index Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sxvNvJbedx2"
   },
   "source": [
    "The default behavior of `pd.read_csv` is to generate an integer index, but you can override this by specifying a column name.\n",
    "\n",
    "We can tell from the previous example that our `college-scorecard-data-scrubbed.csv` has a 'institution_name' column. Let's tell *pandas* to use that as our index. When the data is loaded, the values of that column will become the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C7hQ3jBedx6"
   },
   "outputs": [],
   "source": [
    "# Specify a data column to use as the index\n",
    "college_scorecard = pd.read_csv(\n",
    "    'data-sets/college-scorecard-data-scrubbed.csv', \n",
    "    index_col='institution_name', encoding='latin-1')\n",
    "college_scorecard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I now change my mind about setting 'institution_name' as the DataFrame's index. How do I reset the index back to the default integer form?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see if the index was reset. It wasn't!\n",
    "college_scorecard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to commit the change to a variable, either a new one if you want a new one, or back to itself.\n",
    "\n",
    "# To assign back to itself, you could either do this:\n",
    "# college_scorecard = college_scorecard.reset_index()\n",
    "\n",
    "# or use the inplace option\n",
    "college_scorecard.reset_index(inplace=True)\n",
    "college_scorecard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFftAfGDedyA"
   },
   "source": [
    "### Limiting the Columns to Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7s_AFLhledyD"
   },
   "source": [
    "Data sets will often contain hundreds of data points. But in many cases, we will only be interested in working with a subset of them.\n",
    "\n",
    "When this happens, loading all the data would not only result in a difficult to work with *DataFrame* but would also take up unnecessary computer memory and slow down your processing. \n",
    "\n",
    "Thankfully, we can limit the CSV columns to load via the `usecols` parameter, which takes a list of column names you want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ase3SbJg5PRy"
   },
   "outputs": [],
   "source": [
    "# Download another data for this example from OSF.\n",
    "!curl -L https://osf.io/vesuh/download --create-dirs -o data-sets/college-loan-default-rates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qKXdOV8edyH"
   },
   "outputs": [],
   "source": [
    "# We're only interested in the name, city, and state columns\n",
    "# for all colleges in the loan defaults data set.\n",
    "college_default_rates = pd.read_csv(\n",
    "    'data-sets/college-loan-default-rates.csv',\n",
    "    usecols=['name', 'city', 'state']\n",
    ")\n",
    "college_default_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5S_Px-2PedyN"
   },
   "outputs": [],
   "source": [
    "# You can also specify the columns you want to include \n",
    "# in your DataFrame from the CSV by specifying the column \n",
    "# positions (like always, start with 0).\n",
    "\n",
    "# It is just like specifying index numbers. Start with 0\n",
    "college_default_rates = pd.read_csv(\n",
    "    'data-sets/college-loan-default-rates.csv',\n",
    "    usecols=[0, 1, 2]\n",
    ")\n",
    "college_default_rates.head()\n",
    "\n",
    "# RULE OF THUMB: If a column has a name, use the name! Column positions can change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6n0ZfXTedyU"
   },
   "source": [
    "### Manually Specifying the Column Names\n",
    "The default behavior of `pd.read_csv()` is to use the values found in the first row of the CSV file as the column header values. You can however, override this and manually specify the names of the columns. \n",
    "\n",
    "To do so, you must provide the `names` parameter and often times the `skiprows` parameter:\n",
    "* `names`: Allows you to specify a list of names to use for the column headers.\n",
    "* `skiprows`: Can be passed an `int` indicating the numbers of rows in the data set not to process. *Often times, if you are changing the header names, you are choosing to do so because you don't like the existing ones, not because there aren't any.* Using this parameter allows you to exclude the original ones from being processed and being added to your DataFrame as an additional row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aO4H82HJedyX"
   },
   "outputs": [],
   "source": [
    "# Use the `names` parameter to override the default\n",
    "# column names. \n",
    "college_default_rates = pd.read_csv(\n",
    "    'data-sets/college-loan-default-rates.csv',\n",
    "    usecols=[0, 1, 2], \n",
    "    names=['obtuse_college_id', 'college_name', 'college_address'])\n",
    "college_default_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ub3T7ka1edyd"
   },
   "outputs": [],
   "source": [
    "# In the previous example you can see that the original header names\n",
    "# were still processed and the result wasn't ideal.\n",
    "\n",
    "# Use skiprows to specify the number of rows that \n",
    "# should not be processed from the original data set.\n",
    "college_default_rates = pd.read_csv(\n",
    "    'data-sets/college-loan-default-rates.csv',\n",
    "    usecols=[0, 1, 2], \n",
    "    names=['obtuse_college_id', 'college_name', 'college_address'],\n",
    "    skiprows=1)\n",
    "college_default_rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oObF3Dpbedyh"
   },
   "source": [
    "### Automatically Parsing Dates\n",
    "One of the most painful things to work with in data sets is date conversions. Just thinking about it makes me cringe!\n",
    "\n",
    "Thankfully, Pandas does an awesome job trying to convert various string representations into Python date objects for us if we just ask it to using the `parse_dates` parameter. To demonstrate this, let's load a data set containing information on all of SpaceX's launches. First we will do it without parsing the date(s) and then with date parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xUCj0i57gGI"
   },
   "outputs": [],
   "source": [
    "# Download SpaceX data set\n",
    "!curl -L https://osf.io/xz98h/download --create-dirs -o data-sets/spacex-launch-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgB_YpAQedyk"
   },
   "outputs": [],
   "source": [
    "# Just load the data to get started. You'll see that there is a 'Date'\n",
    "# column which we could tell pandas to parse.\n",
    "space_x = pd.read_csv('data-sets/spacex-launch-data.csv')\n",
    "space_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_kjAyKvedyr"
   },
   "outputs": [],
   "source": [
    "# Without the parsing directive, dates will be treated as \n",
    "# strings, which is problematic for analysis.\n",
    "\n",
    "# Check out the current data type of the 'Date' Series object.\n",
    "# It will be 'O' which stands for object and is used for strings.\n",
    "space_x['Date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wk20X6uEedyy"
   },
   "outputs": [],
   "source": [
    "# But if we pass the 'Date' column name to pd.read_csv via\n",
    "# the `parse_dates` parameter it will convert it \n",
    "# to datatype '<MS8[ns]' - which is a cryptic way of saying a DateTime object.\n",
    "space_x = pd.read_csv('data-sets/spacex-launch-data.csv', parse_dates=['Date'])\n",
    "space_x['Date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pnlHbJ6edy9"
   },
   "outputs": [],
   "source": [
    "# Take another look at the columns in this data set that we printed above.\n",
    "# There is another date-related field, 'Time (UTC)' which represents the\n",
    "# specific time of day that the launch took place.\n",
    "\n",
    "# You can tell Pandas to combine both of those columns into a single data column\n",
    "# by passing a nested list to the `parse_dates` parameter like so:\n",
    "space_x = pd.read_csv(\n",
    "    'data-sets/spacex-launch-data.csv', \n",
    "    parse_dates=[['Date', 'Time (UTC)']])\n",
    "space_x\n",
    "\n",
    "# Make sure to notice how it removes the original two columns and replaces \n",
    "# it with a single one that takes into account both pieces of data. AWESOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much time elapsed between the first flight and the second flight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOIv2W_oedzO"
   },
   "source": [
    "### Leaning More\n",
    "You can learn more about all the other available parameters for the `read_csv` function in the <a href='https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv' target='_blank'>Panda's online documentation.</a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.2 - Pandas Data Loading.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
