{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3.6: Pandas Data Merging\n",
    "Python for Data Analytics | Module 3  \n",
    "Professor James Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: DO NOT CHANGE\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be exploring another way to combine datasets through the `pd.merge()` function.\n",
    "\n",
    "Those who have a background in databases will find a significant amount of overlap between your SQL work and the `pd.merge()` function. But, if you don't have this background, not to worry, we will take it one step at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial, we will be combining data from both the \n",
    "# college load defaults and college scorecard data sets\n",
    "# so we will need to load them both.\n",
    "college_loan_defaults = pd.read_csv(\n",
    "    'datasets/college-loan-default-rates.csv')\n",
    "college_loan_defaults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard = pd.read_csv(\n",
    "    'datasets/college-scorecard-data-scrubbed.csv', \n",
    "    encoding='latin-1')\n",
    "college_scorecard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Difference between `pd.concat()` & `pd.merge()`\n",
    "The essential difference between concatenation and merging is that the latter requires the existence of one or more shared columns (or indices) between the two dataframes.\n",
    "\n",
    "Concatenation has no such requirement. It will simply slap together whatever you give it and fill `NaN` values into spots where there are column/row mismatches.\n",
    "\n",
    "Let's demonstrate this quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the first 5 rows and 2 random columns of college_loan_defaults\n",
    "college_loan_defaults.iloc[:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the same number of elements from college_scorecard\n",
    "college_scorecard.iloc[:5, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are no matching values between these dataframes.  That does not prevent us from concatenating them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating Rows\n",
    "pd.concat([college_loan_defaults.iloc[:5, 2:4], \n",
    "           college_scorecard.iloc[:5, 0:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating Columns\n",
    "pd.concat(\n",
    "    [college_loan_defaults.iloc[:5, 2:4],college_scorecard.iloc[:5, 0:2]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A merge operation could not be performed between these two *DataFrame* objects because they don't have any shared key values to cross-reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 Categories of Merges/Joins\n",
    "There are 3 different categories of merges/joins which are defined by the characteristics of the shared columns/indices:\n",
    "* One-to-One: Each shared key value exists only once in both dataframes.\n",
    "* One-to-Many: A given shared key value exists once in first dataframe, but 1 or more times in the second dateframe.\n",
    "* Many-to-Many: A given shared key value exists 1 or more times in both dataframes.\n",
    "\n",
    "Let's provide an example of each type of merge from our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-One Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that instead of receiving the college scorecard dataset as one whole unit, we had received it in two parts. One dataset had some cost information, and the other had information about median student earnings and debt after attendence.\n",
    "\n",
    "I'll generate these *DataFrame* objects for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_costs = college_scorecard[\n",
    "    ['OPEID', 'average_net_price_public', 'average_net_price_private']][5:10]\n",
    "college_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_outcomes = college_scorecard[\n",
    "    ['OPEID', 'median_student_earnings', 'median_student_debt']][7:12]\n",
    "college_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`OPEID`** field in the college_scorecard dataset is a unique field, which means that each value is guaranteed to only appear once. \n",
    "\n",
    "Because of this, if we merge the two dataframes it will be a 1-1 join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(college_costs, college_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Here's what *pandas* did:\n",
    "1. Identified the matching column(s) between the two dataframes: `OPEID`.\n",
    "1. Found matching `OPEID` values between the two dataframes.\n",
    "1. Merged the columns of matching `OPEID` values together.\n",
    "1. **Important**: Generated a new numeric index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "    In our discussion, we will reference the columns that <em>pandas</em> is using to find matches between dataframes as the \"join column(s)\" or \"merge column(s)\".\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling the Join Type with the `how` Parameter\n",
    "Did you notice that some of the records from each of the original dataframes didn't make it into the merge product?\n",
    "\n",
    "This is because the type of merge that was applied to the dataframes was called an **inner join** - which is the default.\n",
    "\n",
    "The are actually 4 types of joins that you can use in a merge operation:\n",
    "* **Inner Join**: To be included in the output dataframe, the join column(s) value must exist in both original dataframes. \n",
    "    * This is why some of the records didn't get included in the output, because they didn't have a corresponding join column(s) values in the other dataframe.\n",
    "* **Outer Join**: All records from both dataframes are included in the output. *pandas* simply fills in `NaN` where there are no corresponding join column(s) value.\n",
    "* **Left Join**: All rows from the first (left) dataframe will be included in the output dataframe, regardless of whether there are matching join column value(s) in the second (right) dataframe.\n",
    "* **Right Join**: All rows from the second (right) dataframe will be included in the output dataframe, regardless of whether there are matching join column value(s) in the left (first) dataframe.\n",
    "\n",
    "Let's go ahead and try all these different types of joins to see how our output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Join\n",
    "# All records from both dataframes are included.\n",
    "# NaN is inserted into missing grid points.\n",
    "pd.merge(college_costs, college_outcomes, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join\n",
    "# All records from the first/left (college_costs) dataframe are included.\n",
    "# NaN is inserted into missing grid points.\n",
    "pd.merge(college_costs, college_outcomes, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Join\n",
    "# All records from the second/right (college_outcomes) \n",
    "# dataframe are included.\n",
    "# NaN is inserted into missing grid points.\n",
    "pd.merge(college_costs, college_outcomes, how=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-Many Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `college_scorecard` data set has three ID columns: **UNITID**, **OPEID** and **OPEID6**.\n",
    "\n",
    "The reason for this is that universities with multiple locations have multiple records in the scorecard data, but a single `OPEID6` value for the organization as a whole.\n",
    "\n",
    "Let's take a closer look at the duplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichdup = college_scorecard.duplicated(subset=['OPEID6'], keep=False)\n",
    "college_scorecard[whichdup]\n",
    "\n",
    "# Sort this by OPEID and OPEID6 for a better view\n",
    "college_scorecard[whichdup==True].sort_values(by = ['OPEID6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a one-to-many join/merge opportunity for us between the Scorecard data set and the College Loan Defaults data set, which only has 1 instance of each `OPEID6` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's grab the records from `college_scorecard`\n",
    "# for a multi-campus university - Fortis College - that will have \n",
    "# a repeated `OPEID6` value.\n",
    "\n",
    "# We will just grab a couple of columns for this university to\n",
    "# keep things simple.\n",
    "fortis_college = college_scorecard[\n",
    "    college_scorecard['OPEID6'] == 23410][['OPEID', 'OPEID6', 'UNITID', 'institution_name', 'degree_seeking_undergrads', 'students_with_federal_loans']]\n",
    "fortis_college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's grab the corresponding fragement of \n",
    "# the default rates for Fortis College's OPEID\n",
    "fortis_college_default_rate = college_loan_defaults[\n",
    "    college_loan_defaults['opeid'] == 23410][['opeid', 'year_1_default_rate']]\n",
    "fortis_college_default_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and try to perform the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(fortis_college, fortis_college_default_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the Join Columns\n",
    "Well...that isn't want we wanted. :(\n",
    "\n",
    "Thankfully though, the error message is pretty self-explanatory. *pandas* thinks there are no common columns to merge on.\n",
    "\n",
    "The reason for this is that the common values are held in columns with slightly different names. We have to explain to *pandas* what to do when this happens by specifying the names of the columns to join on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the left_on and right_on parameters to specify the\n",
    "# name(s) of the join column(s) in the first(left)\n",
    "# and second (right) dataframes.\n",
    "pd.merge(\n",
    "    fortis_college, \n",
    "    fortis_college_default_rate,\n",
    "    left_on='OPEID6',\n",
    "    right_on='opeid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h5>There can be more than 1 join column</h5>\n",
    "<p>\n",
    "In this example, we have specified only one join column. But you can specify multiple columns if you so desire. Just pass them as a list to the `left_on` and `right_on` parameters.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ah, much better.** You can see (you might have to expand your screen a bit) how *pandas* took the **one** default rate record and applied it to **many** corresponding scorecard records for Fortis College.\n",
    "\n",
    "You could then proceed from this to perform calculations like approximating the number of students in default for each campus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-Many Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a little bit of a stretch to come up with a good many-to-many join example from our two datasets, so let's create a couple of imaginary ones that will illustrate this merge/join category well.\n",
    "\n",
    "We will have two dataframes: \n",
    "* The first will list the members of a work group and their favorite restaurants. \n",
    "* The second will contain some of the foods served by each restaurant. \n",
    "\n",
    "The key here is that a given restaurant has the potential of appearing more than once in both data sets. This sort of situation is what lies behind a \"many-to-many\" merge.  \n",
    "\n",
    "It is easier to see than to explain so let's create our datasets and perform the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Members Favorite Restaurants\n",
    "team_member_favorite_restaurants = pd.DataFrame(\n",
    "    {\n",
    "        'member': ['Mike', 'Kim', 'Roger', 'Sam', 'Sonia'],\n",
    "     'restaurant': ['In-N-Out', 'Chipotle', 'Chick-Fil-A', 'Chick-Fil-A', 'In-N-Out']\n",
    "    }\n",
    ")\n",
    "team_member_favorite_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restaurant Items\n",
    "restaurant_items = pd.DataFrame(\n",
    "    {\n",
    "        'item': [\n",
    "        'Burgers', 'Fries', 'Shakes', \n",
    "        'Tacos', 'Burritos', 'Chips',\n",
    "        'Chicken Sandwich', 'Fries', 'Salads'\n",
    "        ]\n",
    "        ,\n",
    "        'restaurant': [\n",
    "        'In-N-Out', 'In-N-Out', 'In-N-Out', \n",
    "        'Chipotle', 'Chipotle', 'Chipotle',\n",
    "        'Chick-Fil-A', 'Chick-Fil-A', 'Chick-Fil-A'\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "restaurant_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that in our first dataframe, In-N-Out and Chick-Fil-A both appear twice, and all restaurants appear three times in our second dataframe.  Let's perform our merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we're using a combination of columns\n",
    "# and indexes for the \"join columns\"\n",
    "pd.merge(team_member_favorite_restaurants, restaurant_items, \n",
    "         on='restaurant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that many-to-many joins have a multiplicative effect. \n",
    "\n",
    "In practice, many-to-many merge is relatively rare compared to the others, but it is important to understand and can yield some interesting analysis possibilities... such as determining which food item is most likely to be popular with your team.  In this case, the answer is fries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1\n",
    "\n",
    "Merge the two datasets below into a single dataset of annual GDP and happiness in the USA. The first dataset contains GDP and the second dataset contains happiness data. The years in each dataset are not the same. Compare the results of the default inner join, left, right and outer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = pd.read_csv('datasets/happy_annual.csv')\n",
    "dfgdp = pd.read_csv('datasets/gdp_annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfhappy, dfgdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfhappy, dfgdp, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfhappy, dfgdp, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfhappy, dfgdp, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reproduce the figure below, how should you join the two datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datasets/gdphappy0.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the code to generate the above image. \n",
    "# It assumes your merged data are in df_happy_gdp.\n",
    "fig, ax1 = plt.subplots()\n",
    "barhappy = ax1.plot(df_happy_gdp['year'], df_happy_gdp['happy'])\n",
    "ax2 = ax1.twinx()\n",
    "linegdp = ax2.plot(df_happy_gdp['year'], df_happy_gdp['gdppc'], linestyle='dashed', color='green')\n",
    "\n",
    "# add legend\n",
    "barhappy, label1 = ax1.get_legend_handles_labels()\n",
    "linegdp, label2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(barhappy + linegdp, label1 + label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2\n",
    "Merge the two datasets below into a single dataset containing all movies and their user ratings. The first dataset contains movie titles and the second dataset contains movie ratings. You'll have to figure out the column to join on, and how the join should be done (left, right, inner?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('datasets/movie_titles.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('datasets/movie_ratings.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
